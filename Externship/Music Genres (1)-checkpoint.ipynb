{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_features\n",
      "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: python_speech_features\n",
      "  Building wheel for python_speech_features (setup.py): started\n",
      "  Building wheel for python_speech_features (setup.py): finished with status 'done'\n",
      "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5879 sha256=1b4bbdf0a39c7cf3bdb1bf979b7efd7adad5cc36ef9e30978fd4a7fc13ce9bd3\n",
      "  Stored in directory: c:\\users\\vemur\\appdata\\local\\pip\\cache\\wheels\\83\\d7\\64\\696b9812e9f864eb2a2c2a57d5e51465234bd8a9600fdcd183\n",
      "Successfully built python_speech_features\n",
      "Installing collected packages: python_speech_features\n",
      "Successfully installed python_speech_features-0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yfQldLJCi-FE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "import os\n",
    "import pickle \n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dPtdSnvFi-FZ"
   },
   "outputs": [],
   "source": [
    "def distance(instance1 , instance2 , k ):\n",
    "    distance =0 \n",
    "    mm1 = instance1[0] \n",
    "    cm1 = instance1[1]\n",
    "    mm2 = instance2[0]\n",
    "    cm2 = instance2[1]\n",
    "    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1)) \n",
    "    distance+=(np.dot(np.dot((mm2-mm1).transpose() , np.linalg.inv(cm2)) , mm2-mm1 )) \n",
    "    distance+= np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "    distance-= k\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SAdI5yLmi-Fd"
   },
   "outputs": [],
   "source": [
    " def getNeighbors(trainingSet , instance , k):\n",
    "    distances =[]\n",
    "    for x in range (len(trainingSet)):\n",
    "        dist = distance(trainingSet[x], instance, k )+ distance(instance, trainingSet[x], k)\n",
    "        distances.append((trainingSet[x][2], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cC3rzhQoi-Fj"
   },
   "outputs": [],
   "source": [
    "def nearestClass(neighbors):\n",
    "    classVote = {}\n",
    "\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x]\n",
    "        if response in classVote:\n",
    "            classVote[response]+=1 \n",
    "        else:\n",
    "            classVote[response]=1\n",
    "\n",
    "    sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    return sorter[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KfHiG5gUi-Fm"
   },
   "outputs": [],
   "source": [
    "directory =\"E:/Externship/Flask/genres/archive (4)/Data/genres_original/\"\n",
    "f = open(\"my.dat\" ,'wb')\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eRAsmaMi-Fq"
   },
   "outputs": [],
   "source": [
    "for folder in os.listdir(directory):\n",
    "    #as we have 10 classes, we're starting the loop from 1 to 11\n",
    "    #so that we run the loop for total of 10 times, with each folder change (genre change),  i (label) changes. \n",
    "    i += 1\n",
    "    if i==11 :\n",
    "        break   \n",
    "    for file in os.listdir(directory+folder):  \n",
    "        \n",
    "        #To read an Wav audio File in Python\n",
    "        (rate,sig) = wav.read(directory+folder+\"/\"+file)\n",
    "#         print(rate,sig)\n",
    "        #MFCC is the feature we will use for our analysis,\n",
    "        #because it provides data about the overall shape of the audio frequencies.\n",
    "        mfcc_feat = mfcc(sig,rate ,winlen=0.020, appendEnergy = False)\n",
    "        covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "        mean_matrix = mfcc_feat.mean(0)\n",
    "        #making a feature typle that contains the mean matrix from mfcc as well as covariance,\n",
    "        #and last variable in the feature tuple is the label (where numbers correspond to particular genre)\n",
    "        feature = (mean_matrix , covariance , i)\n",
    "        \n",
    "        #This the the created dataset, which takes the input from specified path\n",
    "        #it then stores the feature as a .dat file which can be used later without having to train all the files over it.\n",
    "        pickle.dump(feature , f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EmbkzkPoi-Fx"
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "def loadDataset(project):\n",
    "    with open(\"E:/Externship/Flask/my.dat\" , 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                dataset.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                f.close()\n",
    "                break  \n",
    "\n",
    "loadDataset(\"E:/Externship/Flask/my.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NHOqCHANi-F4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.array(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NakvjukFi-F9"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m x_train ,x_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2233\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2240\u001b[0m     )\n\u001b[0;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train ,x_test = train_test_split(dataset,test_size=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtLf0AE0i-GG"
   },
   "outputs": [],
   "source": [
    "leng = len(x_test)\n",
    "predictions = []\n",
    "for x in range (leng):\n",
    "    predictions.append(nearestClass(getNeighbors(x_train ,x_test[x] , 8))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDQWVFthi-GL"
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    #this is a variable to count total number of correct predictions.\n",
    "    correct = 0 \n",
    "    for x in range (len(testSet)):\n",
    "        if testSet[x][-1]==predictions[x]:\n",
    "            correct+=1\n",
    "    return 1.0*correct/len(testSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpBy6HoPi-GO",
    "outputId": "dbe6a5fe-b654-4bb3-a731-53d3acfb0294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7133333333333334\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = getAccuracy(x_test , predictions)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgXFoUZti-GU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Music Genres (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
